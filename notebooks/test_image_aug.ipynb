{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "sys.path.append(\"../pytorch_resnet_preact\")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import Model, Network, utils, ImageUtils, DataLoader, Configure\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "# Aug1= ImageUtils.ImgAugTransformStandard\n",
    "# Aug2 = ImageUtils.ImgAugTransform1\n",
    "# Aug3 = ImageUtils.ImgAugTransform2\n",
    "Aug1 = ImageUtils.ImgTransformStandard\n",
    "Aug2 = ImageUtils.ImgTransform1\n",
    "Aug3 = ImageUtils.ImgTransform2\n",
    "Aug4 = ImageUtils.ImgTransform3\n",
    "\n",
    "train_1,_,_ = DataLoader.load_data('../data',train_aug=Aug1)\n",
    "train_2,_,_ = DataLoader.load_data('../data',train_aug=Aug2)\n",
    "train_3,_,_ = DataLoader.load_data('../data',train_aug=Aug3)\n",
    "train_4,_,_ = DataLoader.load_data('../data',train_aug=Aug4)\n",
    "\n",
    "train_1 = torch.utils.data.DataLoader(train_1,100,shuffle=False)\n",
    "train_2 = torch.utils.data.DataLoader(train_2,100,shuffle=False)\n",
    "train_3 = torch.utils.data.DataLoader(train_3,100,shuffle=False)\n",
    "train_4 = torch.utils.data.DataLoader(train_4,100,shuffle=False)\n",
    "\n",
    "\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.2470, 1/0.2435, 1/0.2616 ]),\n",
    "                                transforms.Normalize(mean = [ -0.4914, -0.4822, -0.4465 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([30, 3, 32, 32])\n",
      "torch.Size([30, 3, 32, 32])\n",
      "torch.Size([30, 3, 32, 32])\n",
      "torch.Size([30, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "## Generate the plot images for transforms\n",
    "\n",
    "i = 0\n",
    "for ti in [train_1,train_2,train_3,train_4]:\n",
    "    i+=1\n",
    "    for batch_idx, (inputs, targets) in enumerate(ti):\n",
    "        #print(\"Shape of Training Images after TorchTransform\")\n",
    "        print(inputs.shape)\n",
    "        if batch_idx >= 0:\n",
    "            break\n",
    "\n",
    "    images = inputs[0:12]\n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    for idx in np.arange(12):\n",
    "        \n",
    "        image = invTrans(images[idx]).cpu().numpy()\n",
    "        image[image < 0] = 0.0\n",
    "        ax = fig.add_subplot(2, 6, idx+1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.transpose(image.astype(np.float), (1, 2, 0)),interpolation='nearest', aspect='equal')\n",
    "    plt.show()\n",
    "    plt.savefig(str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████▉| 1998/2000 [01:11<00:00, 33.68it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tqdm\n",
    "### Test the computational power needed for transforms:\n",
    "times = np.zeros((4,len(train_1)))\n",
    "\n",
    "train_iter = iter(train_1)\n",
    "    \n",
    "\n",
    "idx = 0\n",
    "pbar = tqdm.tqdm(total=4*len(train_1))\n",
    "\n",
    "for ti in [train_1,train_2,train_3,train_4]:\n",
    "    train_iter = iter(ti)\n",
    "    for i in range(len(train_1)):\n",
    "        t0 = time.time()\n",
    "        _,_ = next(train_iter)\n",
    "        times[idx,i] = time.time() - t0\n",
    "        pbar.update(1)\n",
    "    idx +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('tkagg') # command-line use only\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.hist(times[0]*100,label='Transform Standard',alpha=0.5)\n",
    "plt.hist(times[1]*100,label='Transform1',alpha=0.5)\n",
    "plt.hist(times[2]*100,label='Transform2',alpha=0.5)\n",
    "plt.hist(times[3]*100,label='Transform3',alpha=0.5)\n",
    "plt.xlabel('Execution Time [ms]')\n",
    "plt.ylabel('Freq')\n",
    "plt.title('Execution Performance for Image Augmentations')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ]
}